---
layout: post
title: ' 架构与表设计'
date: '2017-11-16 23:35'
toc: true
tags:
  - mysql
top: 9998
---

# 数据表设计

## 存储引擎
1. **默认使用innodb 引擎**，基本抛弃 myisam（只读也不一定比 innodb 快）
1. **text/blob 垂直拆分后，转成 myisam 表**，innodb 存 blob 会产生大量的磁盘碎片

各存储引擎区别：[存储引擎](/技术之路/数据库/Mysql/基础知识/#数据引擎)

## 字符集
**默认使用utf-8**

注意字符集问题，server=>database(trigger、stored procedure、event scheduler)=>table=>column
不要同时指定字符集（character set）和校验集（collect set），避免出现和默认对应关系不一致

## 字段类型

### 基本原则

1. 越小越好
1. 字段都NOT NULL
  - 默认都加上NOT NULL约束，必须为NULL用0表示
  - 在对该字段进行COUNT(\*)统计时，统计结果更准确（值为NULL的不会被COUNT统计进去）

### 存储技巧
1. **可使用枚举类型**
ENUM的内部存储机制是采用TINYINT或SMALLINT（并非CHAR/VARCHAR），性能一点都不差

1. **存储ipv4地址**
用INT UNSIGNED存储IPV4地址，用INET_ATON()、INET_NTOA()进行转换

1. **存储日期时间**
**一个常识性误导：建议用TIMESTAMP取代DATETIME。**
从5.6开始，建议优先选择DATETIME存储日期时间。因为它的可用范围比TIMESTAMP更大，物理存储上仅比TIMESTAMP多1个字节，整体性能上的损失并不大。

1. **InnoDB表行记录物理长度不超过8KB**
**InnoDB的data page默认是16KB的情况下。**
当实际存储长度超过8KB（尤其有TEXT/BLOB列）且读写频繁的话, 则最好把这些列拆分到子表中，不要和主表放在一起存储。如果不太频繁，可以考虑继续保留在主表中[^1]。

[^1]: [MySQL优化案例]系列 — 优化InnoDB表BLOB列的存储效率

## 索引

1. 显式指定自增 int/bigint unsigned not null 作为主键(有主键 TPS 提升9%，不要使用 uuid，性能差)
2. 选择适当的索引顺序，选择性高条件靠前
2. 基数（ Cardinality ）很低（30%以下）的字段不创建索引（MySQL还不支持 bitmap 索引）
3. 常用排序（ORDER BY）、分组（GROUP BY）、取唯一（DISTINCT）字段上创建索引
4. 单表索引数量不超过5个
5. 不使用外键
5. 超过20个长度的字符串列（不需要排序），创建前缀索引而非整列索引[^6]
  - 优点:有效提高索引利用率
  - 缺点:对这个列排序时用不到前缀索引

[^6]: 例如：`ALTER TABLE t1 ADD INDEX(user(20))`
前缀索引的长度可以基于对该字段的统计得出，一般略大于平均长度一点就可以了。

## 高级特性使用

1. **是否使用分区表？**
在可以提升性能或者运维便利性的场景下，还是建议使用分区表。例如：日志系统，按时间纬度进行分区，方便删除历史数据

1. **是否使用存储过程、触发器？**
单机可用，分布式舍弃。（存储器场景：不变的业务逻辑）

1. **是否使用视图？**
MySQL因为没有物化视图，因此视图尽量少用（不用）

# 缓存与数据库结合
## 读取
### 优缺点
优点：可以减少数据库读取请求
缺点：增加代码复杂度、增加维护难度

### 如何使用？
* 评估进入缓存的数据规模，以及命中率优化[^2]
  - 不是所有数据都适合被缓存，也并不是进入了缓存就意味着效率提升
  - 命中率是第一要评估的数据；**核心在于如何判断哪些属于热点数据**
* 善于利用内存，请注意数据存储的格式及压缩算法。

### 如何确定热点数据
见[下文](#热点数据分表)

[^2]: 实景分析： 前端请求先连接缓存，缓存未命中连接数据库，进行查询，未命中状态比单纯连接数据库查询多了一次连接和查询的操作；如果缓存命中率很低，则这个额外的操作非但不能提高查询效率，反而为系统带来了额外的负载和复杂性，得不偿失。

## 写入
### 优缺点
优点：减少数据库写入`i/o`压力
缺点：数据不能第一时间持久化，有丢失风险

### 如何使用?
缓存实时更新，数据库异步更新（使用队列,请注意使用`increment`来维持队列序号）
- 不要通过`get->处理数据->set->更新数据`的方式维护队列[^3]。 使用`increment`存储队列编号，用标记+编号作为`key`存储队列内容[^4]。
- 后台基于缓存队列读取更新数据并更新数据库[^5]
  - 基于队列读取后可以合并更新
  - **更新合并率**是重要指标

### 异步更新风险
- **前后端同时写，可能导致覆盖风险。**
  - 使用后端异步更新，前端应用程序不要写数据库，否则可能造成写入冲突。
  - 一种兼容的解决方案是，前端和后端不要写相同的字段[^7]。
- **缓存数据丢失或服务崩溃可能导致数据丢失风险。**
  - 如缓存中间出现故障，则缓存队列数据不会回写到数据库，而用户会认为已经完成，此时会带来比较明显的用户体验问题。
  - 一个不彻底的解决方案是，确保高安全性，高重要性数据实时数据更新，而低安全性数据通过缓存异步回写方式完成。此外，使用相对数值操作而不是绝对数值操作更安全[^8][^9]。
- **异步更新如出现队列阻塞可能导致数据丢失风险。**
  - 异步更新通常是使用缓存队列后，在后台由cron或其他守护进程写入数据库。
  - 如果队列生成的速度>后台更新写入数据库的速度，就会产生阻塞，导致数据越累计越多，数据库响应迟缓，而缓存队列无法迅速执行，导致溢出或者过期失效。
  - 解决办法：使用 MQ 队列产品而不使用 memcache 来进行缓存异步更新

[^3]: 范例:
`$var=Memcache_get($memcon,”var”);$var++;memcache_set($memcon,”var”,$var);`
这样一个脚本，使用apache ab去跑，100个并发，跑10000次，然后输出缓存存取的数据，很遗憾，并不是1000，而是5000多，6000多这样的数字，中间的数字全在 get & set的过程中丢掉了。原因：读写间隔中其他并发写入，导致数据丢失。

[^4]: 范例2:
用memcache_increment来做这个操作，同样跑测试会得到完整的10000，一条数据不会丢。

[^5]: 实战范例：
某论坛热门贴，前端不断有views=views+1数据更新请求。
缓存实时更新该状态
后台任务对数据库做异步更新时，假设执行周期是5分钟，那么五分钟可能会接收到这样的请求多达数十次乃至数百次，合并更新后只执行一次update即可。
类似操作还包括游戏打怪，生命和经验的变化；个人主页访问次数的变化等。

[^7]: 实战范例：
用户在线上时，后台异步更新用户状态。管理员后台屏蔽用户是直接更新数据库。结果管理员屏蔽某用户操作完成后，因该用户在线有操作，后台异步更新程序再次基于缓存更新用户状态，用户状态被复活，屏蔽失效。

[^8]: 范例：支付信息，道具的购买与获得，一旦丢失会对用户造成极大的伤害。而经验值，访问数字，如果只丢失了很少时间的内容，用户还是可以容忍的。
[^9]: 范例：如果使用 `Views=Views+…`的操作，一旦出现数据格式错误，从binlog中反推是可以进行数据还原，但是如果使用Views=特定值的操作，一旦缓存中数据有错误，则直接被赋予了一个错误数据，无法回溯！


# 反范式设计（冗余）
- 适度冗余可以减少查询请求
- 适度冗余可以解决分表带来的索引查询问题
- 适度冗余可以解决统计类负载较高的查询问题
- 适度冗余可以减少 io 请求频次，提高 io 支撑能力(cpu 换 io)

## 反范式设计的概念
* 无外键，无连表查询，强调索引,去关联化
* 不考虑触发器及其他内部的存储过程
* 便于分布式设计，允许适度冗余，为了容量扩展允许适度开销。
* 基于业务自由优化，基于i/o 或查询设计，无须遵循范式结构设计。

## 冗余结构设计所面临的典型场景
* 原有展现程序涉及多个表的查询，希望精简查询程序
* 数据表拆分往往基于主键，而原有数据表往往存在非基于主键的关键查询，无法在分表结构中完成。
* 存在较多数据统计需求（count, sum等），效率低下。

## 冗余造成的问题
一致性问题--业务层校验

## 冗余设计方案

### 基于展现的冗余设计
冗余特征：字段简单，更改度不高
为了简化展现程序，在一些数据表中往往存在冗余字段[^13]

[^13]: 举例，信息表 message，存在字段 fromuid,touid,msg,sendtime 四个字段，其中 touid+sendtime是复合索引。存在查询为 select * from message where touid=$uid order by sendtime desc limit 0,30;
展示程序需要显示发送者姓名，此时通常会在message表中增加字段fromusername，甚至有的会增加fromusersex，从而无需连表查询直接输出信息的发送者姓名和性别。这就是一种简单的，为了避免连表查询而使用的冗余字段设计。

### 基于查询的冗余设计
* 涉及分表操作后，一些常见的索引查询可能需要跨表，带来不必要的麻烦。确认查询请求远大于写入请求时，应设置便于查询项的冗余表。
* 冗余表要点
    * 数据一致性，简单说：同增，同删，同更新。
    * 可以做全冗余，或者只做主键关联的冗余，比如通过用户名查询uid，再基于uid查询源表。

实战示例[^10][^11][^12]

[^10]: 实战范例1: 用户分表
将用户库分成若干数据表;基于用户名的查询和基于uid的查询都是高并发请求。
用户分表基于uid分成数据表，同时基于用户名做对应冗余表。
如果允许多方式登陆，可以有如下设计方法：
`uid,passwd,用户信息等等，主数据表，基于uid分表`
`ukey,ukeytype,uid 基于ukey分表，便于用户登陆的查询。分解成如下两个SQL:`
`select uid from ulist_key_13 where ukey=’$username’ and ukeytype=‘login’;`
`select * from ulist_uid_23 where uid=$uid and passwd=’$passwd’;`
`ukeytype定义用户的登陆依据，比如用户名，手机号，邮件地址，网站昵称等。 Ukey+ukeytype 必须唯一`
`此种方式需要登陆密码统一，对于第三方connect接入模式，可以通过引申额外字段完成`

[^11]: 实战范例2：用户游戏积分排名
表结构 uid,gameid,score 参见前文实时积分排行。表内容巨大，需要拆表。
需求1：基于游戏id查询积分排行
需求2：基于用户id查询游戏积分记录
解决方案：建立完全相同的两套表结构，其一以uid为拆表主键，其二以gameid为拆表主键，用户提交积分时，向两个数据结构同时提交。

[^12]: 实战范例3：全冗余查询结构
主信息表仅包括 主键及备注memo字段（text类型），只支持主键查询，可以基于主键拆表。所以需要展现和存储的内容均在memo字段重体现。
对每一个查询条件，建立查询冗余表，以查询条件字段为主键，以主信息表主键id 为内容。
日常查询只基于查询冗余表，然后通过in的方式从主信息表获得内容。
优点是结构扩展非常方便，只需要扩展新的查询信息表即可，核心思路是，只有查询才需要独立的索引结构，展现无需独立字段。
缺点是只适合于相对固定的查询架构，对于更加灵活的组合查询束手无策。

### 基于统计的冗余结构
* 为了减少会涉及大规模影响结果集的表数据操作，比如count，sum操作。应将一些统计类数据通过冗余数据结构保存。
* 冗余数据结构可能以字段方式存在，也可能以独立数据表结构存在，但是都应能通过源数据表恢复。

实战示例[^13]

[^13]: 实战范例：
论坛板块的发帖量，回帖量，每日新增数据等。
网站每日新增用户数等。
参见Discuz论坛系统数据结构，有较多相关结构。
参见前文分段积分结构，是典型用于统计的冗余结构。
后台可以通过源数据表更新该数字。
Redis的Zset类型可以理解为存在一种冗余统计结构。

### 基于 io 压力优化的冗余

**现象：**

单次请求多次写入的情况
  - 请求频次较高，io 压力较大
  - 存在高频读取请求，数据可靠性要求高

**可用方案:**
- 数据压缩存储
- 写入缓存队列
- 通过冗余结构，合并为一次写入[^14][^15]

[^14]: 游戏组队，5个武将。（建立临时的武将表，定时更新到主表）
[^15]: 实时统计

### 历史数据表
历史数据表对应于热点数据表，将需求较少又不能丢弃的数据存入，仅在少数情况下被访问。

# 主从架构

## 基本认识
* 读写分离对负载的减轻远远不如分库分表来的直接。
* 写压力会传递给从表，只读从库一样有写压力，一样会产生读写锁！
* 一主多从结构下，主库是单点隐患，很难解决（如主库当机，从库可以响应读写，但是无法自动担当主库的分发功能）
* 主从延迟也是重大问题。一旦有较大写入问题，如表结构更新，主从会产生巨大延迟。

## 优点
部署简单

## 局限性
* io 压力无法分布，性价比不高（主是多线程写，从是单线程写；分担读压力，不能分担写压力）
* 同步延时避免不了
* 一主多从，主库单点，很难自动故障转移（一从转主，其他从不能自动关联到这个新主）

## 应用场景
一主一从

* 在线热备
* 异地分布
    * 写分布，读统一。
    * 仍然困难重重，受限于网络环境问题巨多！
* 自动障碍转移
    * 主崩溃，从自动接管
* 个人建议，负载均衡主要使用分库方案，主从主要用于热备和障碍转移。

## 潜在优化点
为了减少写压力，有些人建议主不建索引提升i/o性能，从建立索引满足查询要求。个人认为这样维护较为麻烦。而且从本身会继承主的i/o压力，因此优化价值有限。该思路特此分享，不做推荐(caoz观点)。

# 分布式设计
- 设计分布式之前，先优化单机：
- 单机读 qps 几千很容易
- 单机写 qps 几千很容易
- 数据量最少在3000万以上（具体业务具体分析）

## 目标
### 防止单点隐患
**lvs nginx（轮询，自动切换）**

* 所谓单点隐患，就是某台设备出现故障，会导致整体系统的不可用，这个设备就是单点隐患。
* 理解连带效应，所谓连带效应，就是一种问题会引发另一种故障，举例而言，memcache+mysql是一种常见缓存组合，在前端压力很大时，如果memcache崩溃，理论上数据会通过mysql读取，不存在系统不可用情况，但是mysql无法对抗如此大的压力冲击，会因此连带崩溃。因A系统问题导致B系统崩溃的连带问题，在运维过程中会频繁出现。[^16][^17]
    * 连带效应是常见的系统崩溃，日常分析崩溃原因的时候需要认真考虑连带效应的影响，头疼医头，脚疼医脚是不行的。

[^16]: 实战范例： 在mysql连接不及时释放的应用环境里，当网络环境异常（同机房友邻服务器遭受拒绝服务攻击，出口阻塞），网络延迟加剧，空连接数急剧增加，导致数据库连接过多崩溃。
[^17]: 实战范例：前端代码 通常我们封装 mysql_connect和memcache_connect，二者的顺序不同，会产生不同的连带效应。如果mysql_connect在前，那么一旦memcache连接阻塞，会连带mysql空连接过多崩溃。

### 方便系统扩容

* 数据容量增加后，要考虑能够将数据分布到不同的服务器上。
* 请求压力增加时，要考虑将请求压力分布到不同服务器上。
* 扩容设计时需要考虑防止单点隐患。

### 安全可控，成本可控

* 数据安全，业务安全
* 人力资源成本 > 带宽流量成本 > 硬件成本
    * 成本与流量的关系曲线应低于线性增长（流量为横轴，成本为纵轴）。
    * 规模优势

## 分库&分表
### 优点
* 负载分担较好
* 不存在同步延迟
* 拆分方法灵活

### 局限性
* 需要有备份和自动故障转移的方案
* 需要应用端配合，无法完全满足关联查询的需求

### 推荐方案
* 以分库、分表为负载和数据支撑方案
* 以主从结构为热备和故障转移方案
* 使用中间件作为分布式数据库的前端（amoeba，要去关联化）
* 数据一致性问题解决
    * 前端校验
    * 后端 cron 定时跑数据

### 基本认识
* 用分库&拆表是解决数据库容量问题的唯一途径。
* 分库&拆表也是解决性能压力的最优选择。
* 分库 – 不同的数据表放到不同的数据库服务器中（也可能是虚拟服务器）
* 拆表 – 一张数据表拆成多张数据表，可能位于同一台服务器，也可能位于多台服务器（含虚拟服务器）。

### 去关联化原则
* 摘除数据表之间的关联，是分库的基础工作。
* 摘除关联的目的是，当数据表分布到不同服务器时，查询请求容易分发和处理。
* 学会理解反范式数据结构设计，所谓反范式，第一要点是不用外键，不允许Join操作，不允许任何需要跨越两个表的查询请求。第二要点是适度冗余减少查询请求[^18]
* 去关联化处理会带来额外的考虑，比如说，某一个数据表内容的修改，对另一个数据表的影响。这一点需要在程序或其他途径去考虑。

[^18]: 比如说，信息表，fromuid, touid, message字段外，还需要一个fromuname字段记录用户名，这样查询者通过touid查询后，能够立即得到发信人的用户名，而无需进行另一个数据表的查询。

### 分库方案
#### 安全性拆分
运维优化，易于管理
* 将高安全性数据与低安全性数据分库，这样的好处第一是便于维护，第二是高安全性数据的数据库参数配置可以以安全优先，而低安全性数据的参数配置以性能优先。参见运维优化相关部分。
* 安全性开启参数：sync_binlog，innodb_flush_log_at_trx_commit = 2(丢失最后1s 数据);开启后性能下降10~100倍

#### 基于业务逻辑拆分
易于管理，对应用端友好，负载不能均分

* 根据数据表的内容构成，业务逻辑拆分，便于日常维护和前端调用。
* 基于业务逻辑拆分，可以减少前端应用请求发送到不同数据库服务器的频次，从而减少链接开销。
* 基于业务逻辑拆分，可保留部分数据关联，前端web工程师可在限度范围内执行关联查询。

#### 基于负载压力拆分
负载相对可以均摊；管理不方便

* 基于负载压力对数据结构拆分，便于直接将负载分担给不同的服务器。
* 基于负载压力拆分，可能拆分后的数据库包含不同业务类型的数据表，日常维护会有一定的烦恼。

#### 混合拆分组合
* 基于安全与业务拆分为数据库实例，但是可以使用不同端口放在同一个服务器上。
* 基于负载可以拆分为更多数据库实例分布在不同数据库上

例如:
* 基于安全拆分出A数据库实例，
* 基于业务拆分出B,C数据库实例，
* C数据库存在较高负载，基于负载拆分为C1,C2,C3,C4等 实例。
* 数据库服务器完全可以做到 A+B+C1为一台，C2,C3,C4各单独一台。

### 分表方案
数据量过大或者访问压力过大的数据表需要切分

#### 纵向分表（常见为忙闲分表）
* 单数据表字段过多，可将频繁更新的整数数据与非频繁更新的字符串数据切分[^19]
* 过于频繁的，使用 nosql（memcached，redis 等）

[^19]: 范例: user表 ，个人简介，地址，QQ号，联系方式，头像 这些字段为字符串类型，更新请求少； 最后登录时间，在线时常，访问次数，信件数这些字段为整数型字段，更新频繁，可以将后面这些更新频繁的字段独立拆出一张数据表，表内容变少，索引结构变少，读写请求变快。

#### 横向切表
* 等分切表，如哈希切表或其他基于对某数字取余的切表。等分切表的优点是负载均分；缺点是当容量继续增加时无法方便的扩容，需要重新进行数据的切分或转表。而且一些关键主键不易处理。（只能基于差存条件进行拆分，否则没法查询）
* 递增切表，比如每1kw用户开一个新表，优点是可以适应数据的自增趋势；缺点是往往新数据负载高（最新的表），压力分配不平均。
* 日期切表，适用于日志记录式数据，优缺点等同于递增切表。
* 个人倾向于递增切表，具体根据应用场景决定。

#### 热点数据分表
将数据量较大的数据表中将读写频繁的数据抽取出来，形成热点数据表。通常一个庞大数据表经常被读写的内容往往具有一定的集中性，如果这些集中数据单独处理，就会极大减少整体系统的负载。

**热点数据表与旧有数据关系:**
* 可以是一张冗余表，即该表数据丢失不会妨碍使用，因源数据仍存在于旧有结构中。优点是安全性高，维护方便，缺点是写压力不能分担，仍需要同步写回原系统。
* 可以是非冗余表，即热点数据的内容原有结构不再保存，优点是读写效率全部优化；缺点是当热点数据发生变化时，维护量较大。
* 具体方案选择需要根据读写比例决定，在读频率远高于写频率情况下，优先考虑冗余表方案。

**数据存储：**
热点数据表可以用单独的优化的硬件存储，比如昂贵的闪存卡或大内存系统。

**热点数据表的重要指标:**
* 热点数据的定义需要根据业务模式自行制定策略，常见策略为，按照最新的操作时间；按照内容丰富度等等。
* 数据规模，比如从1000万条数据，抽取出100万条热点数据。
* 热点命中率，比如查询10次，多少次命中在热点数据内。
* 理论上，数据规模越小，热点命中率越高，说明效果越好。需要根据业务自行评估。

**热点数据表的动态维护:**
* 加载热点数据方案选择
    * 定时从旧有数据结构中按照新的策略获取
    * 在从旧有数据结构读取时动态加载到热点数据
* 剔除热点数据方案选择
    * 基于特定策略，定时将热点数据中访问频次较少的数据剔除
    * 如热点数据是冗余表，则直接删除即可，如不是冗余表，需要回写给旧有数据结构。

通常，热点数据往往是基于缓存或者key-value方案冗余存储，所以这里提到的热点数据表，其实更多是理解思路，用到的场合可能并不多。（适合组合条件场景，数据规模中等，像淘宝的数据量就需要第三方搜索引擎）


# 参考资料
* [[MySQL优化案例]系列 — 优化InnoDB表BLOB列的存储效率](
http://imysql.com/2014/09/28/mysql-optimization-case-blob-stored-in-innodb-optimization.shtml)
* 《Mysql 性能优化教程-曹政》


<!--以下是脚注-->
